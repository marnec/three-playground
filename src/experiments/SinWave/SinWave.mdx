import SinWaveGrid from "./SinWaveGrid"
import SinWavePlane from "./SinWavePlane"
import ExperimentSceneWrapper from '../../components/ExperimentSceneWrapper.tsx'
import SinWaveBox from './SinWaveBox.tsx'


<ExperimentSceneWrapper fullWidth={true}>
  <SinWavePlane />
</ExperimentSceneWrapper>

I was always fascinated by wave-like motion. I find it calming and
hypnotic.

I knew that to achieve a wave-like effect I would have to use a wave
function somewhere, the first that comes to mind is the sine function
$\sin(\alpha)$. Since $\alpha$ is an angle, its value is expected to be
$0 < \alpha < 2\pi$, but I don't really care about it being an angle,
I only care about the fact that this function returns values in the form
of an infinitely cyclical wave for increasing values of $\alpha$.

This means that I can use this values to set the height of some visual
elements so that they resemble a wave pattern.

The first strategy that came to my mind was to just draw an $n$ by $n$ grid of
simple objects, in this case they are spherical meshes. I didn't bother
with instantiation for performance optimization, they are just a bunch
of spherical geometry meshes placed in a grid.
Then I recentered the grid by translating all mesh coordinates by $-n/2$.

At this point I knew that I needed to set the $y$ coordinate as the
value of $\sin(\alpha)$ using the distance from the center $\alpha=d$.
Where $d$ is the Euclidean distance of a point $(xz)$ from the center.

$$
d=\sqrt{x^2 + z^2}
$$

<ExperimentSceneWrapper>
  <SinWaveGrid isAnimated={1} />
</ExperimentSceneWrapper>

Now it's time to animate the motion. The animation is just based on
elapsed time $t$. The $y$ coordinate is computed at every frame as the
sine of $t$ plus $d$.

$$
y = \sin(d + t)
$$

For each point $(xz)$, its distance from the center $d_xz$ provides the initial $y$ 
coordinate and doesn't change along time, while $t$ keeps increasing, moving every
single mesh up and down with the values of the sine function.

---

The actual result I wanted to get to was to animate a surface in a
similar way. I created a mesh and given it a `PlaneGeometry` with
50 segments on both axes. By default, `PlaneGeometry`s are created
on the $[xy]$ so I rotated it by $\pi/2$ radians along the $x$ axis.

Now I needed to do something similar to what I did for the vertical position
of spheres to the vertical position of vertex.

<ExperimentSceneWrapper>
  <SinWavePlane />
</ExperimentSceneWrapper>

It was a bit of a pain to understand how to modify the position of vertices
in a `BufferGeometry` because it required to extract the coordinates as
`BufferAttribute`s. From what I can gather threejs now always stores
geometries as buffer geometries, that are based on a more efficient data but
harder to handle data structure.

---

While trying to animate the plane geometry, I noticed in the threejs documentation
that there was a bunch of other geometries and so I wondered if I could apply the
wave motion to a face of a 3d geometry.

<ExperimentSceneWrapper> 
  <SinWaveBox />
</ExperimentSceneWrapper>

I chose arguably the simplest 3d geometry: `BoxGeometry`. I tried to apply the same
principle used for the `PlaneGeometry` but I found out that they are organized in a 
different way: the vertices are stored in a single array of flat coordinates as for
the `PlaneGeometry`, but each face of the cube is assigned to a different `group`, 
each storing the range of indexes that belong to that `group` (and thus that face).

I chose the first group/face that ended up being $x_+$. This means that the coordinate
that I needed to displace was $x$ and thus we can say $x=sin(t + d)$. 

I soon discovered that that was not enough: the original coordinate this time was not $0$ 
like the other experiments. This time the origin $x_{t_0}$ was half of the width 
$w$ of the geometry. So for each instant $t_i$ I had compute:

$$
x_{t_i} = x_{t_0} + sin(t + d)
$$

With $x_{t_0} = w/2$.


Another pain point about this was about the edges of the animated face. If you look at
the `PlaneGeometry` example, you'll see that the edges float around. I thought that the
vertices of the adjacent faces would automatically connect to the vertices of the animated
face. Well I was wrong. 

Apparently, each face is completely independent and animating just
one face created floating detached vertices at the edges. I could solve this problem by
either animating the edge vertices of the adjacent faces or by fixing in-place the edge
vertices of the animated face. I went with the second option.

To fix them in place I created a smooth dampening that reduces the ondulation
as a function of the distance from center, with 0 motion at the edges. The dampen $m$ is
calculated as:

$$
m = 1 - \frac{d}{\max{(d)}}
$$

It's a bit cumbersome to calculate $\max{(d)}$, because it depends on the angle of the
vector $\begin{pmatrix}y \\ z\end{pmatrix}$. 

$$
\max{(d)} = \min{(\max{(dy)},\max{(dz)})}
$$

Where $dy=\frac{x_{t_{0}}}{|\cos{(\alpha)}|}$

And $dz=\frac{x_{t_{0}}}{|\sin{(\alpha)}|}$

And $\alpha=\tan{(z, y)}$ calculated with the `atan2` implementation, which returns angle values in $(0, 2\pi]$.

---

There's a thing that I increasingly realized by working on this experiments. This is for sure 
a type of work that can be done in shaders and thus offloaded to the cpu. This is also the
reason why I didn't focus on optimization here as I'm planning to reproduce this work in shaders.

But now it's still too early for that. Shaders are hard and there are many things I want to try
out that don't require them. I'll get a better feeling of the tool first and then I'll probably wander
off in the land of shaders.
