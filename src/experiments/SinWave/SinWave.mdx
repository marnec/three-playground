import SinWaveGrid from "./SinWaveGrid"
import SinWavePlane from "./SinWavePlane"
import ExperimentSceneWrapper from '../../components/ExperimentSceneWrapper.tsx'
import SinWaveBox from './SinWaveBox.tsx'


<ExperimentSceneWrapper fullWidth={true}>
  <SinWavePlane />
</ExperimentSceneWrapper>

I was always fascinated by wave-like motion. I find it calming and
hypnotic.

I knew that to achieve a wave-like effect I would have to use a wave
function somewhere, and the first that comes to mind is the sine function
$\sin(\alpha)$. Mathematically, $\alpha$ represents an angle and is expected to be
in the range $0 < \alpha < 2\pi$. But here's the thing: I don't actually need it
to represent an angle. What matters is the key property of the sine function: it
produces a smooth, continuously oscillating output that cycles between -1 and 1
as its input increases.

This means I can use these oscillating values to control the height of visual
elements, making them rise and fall in a wave pattern.

The first strategy that came to my mind was to draw an $n$ by $n$ grid of
simple objects, in this case, spherical meshes. I didn't bother with
instanced rendering for performance optimization; they're just individual
sphere geometry meshes placed in a grid pattern.

By default, a grid starting at $(0, 0)$ would have all spheres in one quadrant.
To center the wave effect, I translated all mesh coordinates by $-n/2$, placing
the origin at the middle of the grid.

To create a circular wave emanating from the center,
I needed each sphere's height to depend on its distance from the origin. So I set
the $y$ coordinate as the value of $\sin(d)$, where $d$ is the Euclidean distance
of a point $(x, z)$ from the center:

$$
d=\sqrt{x^2 + z^2}
$$

Spheres close to the center have a small $d$, while those at the edges have a
large $d$. Since $\sin$ oscillates as its input grows, this naturally creates
concentric rings of varying height in a wave pattern.

<ExperimentSceneWrapper>
  <SinWaveGrid isAnimated={1} />
</ExperimentSceneWrapper>

Now it's time to animate the motion. The idea is to add elapsed time $t$ to
our distance value. On every frame, the $y$ coordinate is recomputed as:

$$
y = \sin(d + t)
$$

Each sphere has a fixed distance $d$ from the center that
never changes. But $t$ keeps increasing as time passes. Adding them together
means each sphere's sine input continuously grows, causing it to oscillate up
and down. And because different spheres have different $d$ values, they're all
at different phases of the oscillation, which is exactly what makes the wave
appear to ripple outward from the center.

---

The actual result I wanted to achieve was to animate a continuous surface in a
similar way. I created a mesh with a `PlaneGeometry` using 50 segments on both
axes, which allows for a smoother wave
deformation. By default, `PlaneGeometry` is created on the $xy$ plane, so I
rotated it by $\pi/2$ radians along the $x$ axis to lay it flat horizontally.

Now I needed to do something similar to what I did for the vertical position
of spheres: for each vertex, compute its distance from the center and use that to determine its height
via the sine function.

<ExperimentSceneWrapper>
  <SinWavePlane />
</ExperimentSceneWrapper>

The tricky part was figuring out how to actually modify vertex positions.
In Three.js, geometries are stored as `BufferGeometry`, which uses flat typed
arrays for performance. Vertex positions live in a `BufferAttribute` called
`position`, stored as a contiguous array where every three consecutive values
represent one vertex's $(x, y, z)$ coordinates. To animate the wave, I loop
through this array, calculate the distance for each vertex, and update its
height accordingly. Another tricky part is that you need to set
`geometry.attributes.position.needsUpdate = true` to tell Three.js to
re-upload the data to the GPU, otherwise you won't see your changes (not always at least).

---

While working on the plane, I noticed in the Three.js documentation that there
were many other built-in geometries. This made me wonder: could I apply the same
wave motion to just one face of a 3D shape?

<ExperimentSceneWrapper>
  <SinWaveBox />
</ExperimentSceneWrapper>

I chose arguably the simplest 3D geometry: `BoxGeometry`. I tried to apply the
same principle used for the `PlaneGeometry`, but discovered that box geometries
are organized differently. While vertices are still stored in a single flat
array of coordinates, each face of the cube is assigned to a different `group`.
Each group stores the range of vertex indices that belong to it, allowing you
to identify and manipulate specific faces.

I targeted the first group, which turned out to be the $x_+$ face (the face
pointing in the positive x direction). Since this face is perpendicular to the
x-axis, the coordinate I needed to displace was $x$, giving us $x = \sin(t + d)$.

But I soon discovered that wasn't quite right. In the previous experiments, the
vertices started at $y = 0$, so the sine displacement directly became the new
position. This time, the face isn't at the origin, it sits at $x = w/2$, where
$w$ is the width of the box. So the displacement needs to be added to the
original position rather than replacing it:

$$
x_{t_i} = x_{t_0} + \sin(t + d)
$$

Where $x_{t_0} = w/2$ is the resting position of the face.


Another challenge was dealing with the edges of the animated face. If you look
at the `PlaneGeometry` example, you'll notice the edges float freely in space.
I initially assumed that vertices shared between adjacent faces would stay
connected automatically. I was wrong.

In a `BoxGeometry`, each face has its own independent set of vertices. They
don't share vertices with neighboring faces, even at the edges. So when I
animated just one face, gaps appeared where the moving vertices pulled away
from the stationary adjacent faces.

I had two options: animate the edge vertices of neighboring faces to match,
or constrain the animated face's edges to stay in place. I went with the
second approach.

To achieve this, I created a smooth dampening factor that reduces the wave
amplitude as a function of distance from the center, reaching zero at the
edges. This way, edge vertices stay fixed while the center of the face
undulates freely. The dampening multiplier $m$ is calculated as:

$$
m = 1 - \frac{d}{d_{max}}
$$

At the center ($d = 0$), the multiplier is $m = 1$, meaning full wave amplitude.
At the edges ($d = d_{max}$), the multiplier becomes $m = 0$, meaning no movement.

The painful part is calculating $d_{max}$, the maximum distance from the center
to the edge. Since the face is rectangular rather than circular, this maximum
distance depends on the direction you're measuring in. A vertex directly above
the center reaches the edge at a different distance than one at a 45Â° angle
toward a corner.

To handle this, I compute the distance to the edge along both the $y$ and $z$
axes based on the vertex's angle $\alpha$ from the center:

$$
d_{max} = \min(d_y, d_z)
$$

Where $d_y = \frac{h/2}{|\cos(\alpha)|}$ and $d_z = \frac{w/2}{|\sin(\alpha)|}$,
with $h$ and $w$ being the height and width of the face.

The angle $\alpha = \text{atan2}(z, y)$ gives us the direction from the center
to each vertex. By taking the minimum of the two distances, we get the actual
distance to whichever edge the vertex would hit first.

---

One thing I increasingly realized while working on these experiments: this type
of per-vertex computation is exactly what shaders are designed for. Instead of
looping through vertices on the CPU every frame, a vertex shader could perform
these calculations in parallel on the GPU, which would be far more efficient.

But shaders have a steep learning
curve, and there's still plenty I want to explore with the JavaScript API.
I'll build up my intuition for the tool first, and eventually go into
shader territory.
